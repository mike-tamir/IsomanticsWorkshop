{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# T_Matrix-Spectral_Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_de_T.csv       en_zh-CN_T.csv    fr_ru_T.csv       ru_it_T.csv\r\n",
      "de_en_T.csv       es_de_T.csv       fr_zh-CN_T.csv    ru_ru_T.csv\r\n",
      "de_es_T.csv       es_en_T.csv       it_de_T.csv       ru_zh-CN_T.csv\r\n",
      "de_fr_T.csv       es_es_T.csv       it_en_T.csv       zh-CN_de_T.csv\r\n",
      "de_it_T.csv       es_fr_T.csv       it_es_T.csv       zh-CN_en_T.csv\r\n",
      "de_ru_T.csv       es_it_T.csv       it_fr_T.csv       zh-CN_es_T.csv\r\n",
      "de_zh-CN_T.csv    es_ru_T.csv       it_it_T.csv       zh-CN_fr_T.csv\r\n",
      "en_de_T.csv       es_zh-CN_T.csv    it_ru_T.csv       zh-CN_it_T.csv\r\n",
      "en_en_T.csv       fr_de_T.csv       it_zh-CN_T.csv    zh-CN_ru_T.csv\r\n",
      "en_es_T.csv       fr_en_T.csv       ru_de_T.csv       zh-CN_zh-CN_T.csv\r\n",
      "en_fr_T.csv       fr_es_T.csv       ru_en_T.csv\r\n",
      "en_it_T.csv       fr_fr_T.csv       ru_es_T.csv\r\n",
      "en_ru_T.csv       fr_it_T.csv       ru_fr_T.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./test_l3_l2_T/T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix de_de_T.csv loaded with shape (300, 300).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'de_de': array([[  2.62798872e-02,  -8.00443720e-03,   9.06144828e-03, ...,\n",
       "           4.51286905e-04,  -6.37024525e-04,  -6.43303106e-03],\n",
       "        [ -7.71387713e-03,   3.17478180e-02,  -1.03924386e-02, ...,\n",
       "          -3.13700526e-03,   1.11302815e-03,   9.44260973e-03],\n",
       "        [  8.97303317e-03,  -1.00596156e-02,   3.05041317e-02, ...,\n",
       "           5.88151684e-04,   6.44203828e-06,  -7.75917433e-03],\n",
       "        ..., \n",
       "        [  8.34789593e-04,  -3.14916088e-03,   6.72287075e-04, ...,\n",
       "           1.96522009e-02,  -1.65478152e-04,   1.01957284e-03],\n",
       "        [  1.29190652e-04,   3.62422550e-04,   2.75136787e-04, ...,\n",
       "           1.05115771e-03,   1.94369927e-02,   1.32160319e-03],\n",
       "        [ -6.42255787e-03,   8.82536173e-03,  -7.61175994e-03, ...,\n",
       "          -4.40414988e-05,   1.17071450e-03,   2.85430402e-02]])}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### Set args\n",
    "\n",
    "\n",
    "T_MATRIX_DIR = \"./test_l3_l2_T/T\"\n",
    "VERBOSE = 3\n",
    "#######\n",
    "\n",
    "### Map args\n",
    "T_matrix_dir = T_MATRIX_DIR\n",
    "verbose = VERBOSE\n",
    "#######\n",
    "\n",
    "# create a list of items in T_matrix_dir\n",
    "T_matrix_dir_items = os.listdir(T_matrix_dir)\n",
    "\n",
    "# Loop through list of paths to process each matrix\n",
    "T_matrix_dict = {}\n",
    "for T_matrix_name in T_matrix_dir_items[:1]:\n",
    "    \n",
    "    # Create path name\n",
    "    T_matrix_full_path = os.path.join(T_matrix_dir, T_matrix_name)\n",
    "    \n",
    "    # Extract language strings and extensions\n",
    "    [T_matrix_lgs, T_matrix_ext] = T_matrix_name.split(\".\")\n",
    "    T_matrix_lgs = T_matrix_lgs.rstrip(\"_T\")\n",
    "    \n",
    "    # Filter for non csv extensions\n",
    "    if T_matrix_ext != \"csv\":\n",
    "        if verbose >= 1:\n",
    "            print(\"Skipping %s item in %s: extenion is not '.csv'\" % (T_matrix_name,T_matrix_dir))\n",
    "    \n",
    "    else:\n",
    "        # Load in csv as numpy array\n",
    "        T_matrix = np.loadtxt(open(T_matrix_full_path), delimiter=\",\")\n",
    "        \n",
    "        ### Add matrices to T_matrix_dict under Lg1-Lg-2 key\n",
    "        T_matrix_dict[T_matrix_lgs] = {}\n",
    "        \n",
    "        # Raw matrix\n",
    "        T_matrix_dict[T_matrix_lgs][\"T_matrix\"] = T_matrix\n",
    "        \n",
    "        # T_cov Covariance matrix TT^{T}\n",
    "        T_cov = np.dot(T_matrix,T_matrix.T)\n",
    "        T_matrix_dict[T_matrix_lgs][\"T_cov\"] = T_cov\n",
    "        \n",
    "        # T_inv Matrix Inverse T^{-1}\n",
    "        \n",
    "        # SVD U, \\Sigma matrix, and V matrices\n",
    "\n",
    "        ### Add language dict to full T_matrix_dict\n",
    "         = lang_dict\n",
    "\n",
    "        \n",
    "        if verbose >= 2:\n",
    "            print(\"Matrix %s loaded with shape %r.\" % (T_matrix_name, T_matrix.shape))\n",
    "        \n",
    "    \n",
    "# print(T_matrix_lgs)\n",
    "#     print(T_matrix_ext)\n",
    "#     print(type(T_matrix_ext))\n",
    "T_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 94.89567226,  20.35967357,   6.7718968 , ...,   2.34332517,\n",
       "         24.51701224,  -9.82782042],\n",
       "       [ -2.96051441,  94.05096546,  20.97794425, ..., -15.18881932,\n",
       "        -24.88619172,  80.05241732],\n",
       "       [-22.65918501, -32.7518761 ,  53.05976914, ...,  -9.98179643,\n",
       "        -21.08009261,   6.24493535],\n",
       "       ..., \n",
       "       [ -8.57743751,  48.60726184,  29.88192204, ...,  86.94535171,\n",
       "         -3.71001585,  72.91735552],\n",
       "       [ 12.25899103,  -3.53288459,  16.69945066, ..., -19.36209148,\n",
       "         78.07405285,  71.57359398],\n",
       "       [-11.04576256, -23.58286134, -11.4602463 , ..., -18.75958708,\n",
       "        -12.94199067,  90.87706923]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_inv = np.linalg.inv(T_matrix)\n",
    "T_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ..., -0.,  0., -0.],\n",
       "       [-0.,  1.,  0., ...,  0.,  0., -0.],\n",
       "       [-0.,  0.,  1., ..., -0., -0., -0.],\n",
       "       ..., \n",
       "       [ 0.,  0., -0., ...,  1.,  0., -0.],\n",
       "       [-0., -0., -0., ..., -0.,  1.,  0.],\n",
       "       [-0.,  0.,  0., ..., -0.,  0.,  1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_by_T_inv = np.dot(T_matrix,T_inv)\n",
    "T_by_T_inv.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0039021673627 0.0039021673627 0.0037940085339\n",
      "-0.0040473810079 -0.0040473810079 -0.00399833613247\n",
      "0.00376721735933 0.00376721735933 0.00374123077432\n",
      "0.00498599789147 0.00498599789147 0.00487901977073\n",
      "-0.00290273117037 -0.00290273117037 -0.00298954902859\n",
      "-0.00462010470051 -0.00462010470051 -0.0045701257852\n",
      "0.00315507558325 0.00315507558325 0.00312181978561\n",
      "0.00151320939132 0.00151320939132 0.00148532907157\n",
      "-0.00154726999838 -0.00154726999838 -0.00138808441207\n",
      "-0.00270270669324 -0.00270270669324 -0.00261390635519\n",
      "-0.000159819712855 -0.000159819712855 6.03619384976e-05\n",
      "-0.000700569593592 -0.000700569593592 -0.000577766333886\n",
      "-0.00173720331016 -0.00173720331016 -0.00171835028524\n",
      "0.000719008720446 0.000719008720446 0.000735821365039\n",
      "0.00145545696889 0.00145545696889 0.00148244058903\n",
      "-0.00042235767253 -0.00042235767253 -0.000326039419624\n",
      "0.00245874578166 0.00245874578166 0.00251467699738\n",
      "-0.00235781305297 -0.00235781305297 -0.00233614585772\n",
      "0.00147591203399 0.00147591203399 0.00142351436705\n",
      "-0.00147738197572 -0.00147738197572 -0.00145471469225\n",
      "-0.00121042248881 -0.00121042248881 -0.00114042134307\n",
      "-0.00190696089782 -0.00190696089782 -0.00187546286458\n",
      "3.54057377682e-05 3.54057377682e-05 2.07639832958e-05\n",
      "-0.000459052611384 -0.000459052611384 -0.000647908383009\n",
      "0.000398689326999 0.000398689326999 0.000405718336701\n",
      "0.00264514250332 0.00264514250332 0.00260322865157\n",
      "0.00113849041701 0.00113849041701 0.00108713288839\n",
      "-0.000950345208653 -0.000950345208653 -0.00103463577015\n",
      "0.00324658799406 0.00324658799406 0.00318050571894\n",
      "0.00303198212534 0.00303198212534 0.00301825764626\n",
      "-0.00301325261038 -0.00301325261038 -0.00312743636616\n",
      "-0.00222268661844 -0.00222268661844 -0.00234010511018\n",
      "-0.000680842192789 -0.000680842192789 -0.00053573997644\n",
      "0.00209724983244 0.00209724983244 0.00218221566268\n",
      "0.00228917814839 0.00228917814839 0.00225409778479\n",
      "0.00136714157029 0.00136714157029 0.00126230547438\n",
      "0.00184475413086 0.00184475413086 0.00169690949327\n",
      "0.00174268066493 0.00174268066493 0.00155975811738\n",
      "0.00187497288173 0.00187497288173 0.00173761266233\n",
      "-0.00174092103698 -0.00174092103698 -0.00173667009296\n",
      "0.000925632497694 0.000925632497694 0.000824420258921\n",
      "0.000989167669073 0.000989167669073 0.00099193246985\n",
      "0.00221987383591 0.00221987383591 0.00227724070247\n",
      "-0.0037243708465 -0.0037243708465 -0.0036435884119\n",
      "-0.00102140864238 -0.00102140864238 -0.00103218678882\n",
      "0.00256108196381 0.00256108196381 0.00240288033872\n",
      "-0.000835409440326 -0.000835409440326 -0.000804202080792\n",
      "0.000902824003026 0.000902824003026 0.000817695135422\n",
      "-0.000929483934478 -0.000929483934478 -0.000896530287084\n",
      "0.00175169484921 0.00175169484921 0.00183607919578\n",
      "-0.00141190706822 -0.00141190706822 -0.00146674087469\n",
      "-0.000221164408904 -0.000221164408904 -0.000260251891694\n",
      "-0.000532599991695 -0.000532599991695 -0.000674714837301\n",
      "-0.0012254527523 -0.0012254527523 -0.00135492298791\n",
      "-0.00106914465982 -0.00106914465982 -0.00108633510614\n",
      "0.00117644700574 0.00117644700574 0.00103838740407\n",
      "0.00186445874267 0.00186445874267 0.00210634723428\n",
      "0.00096802965591 0.00096802965591 0.000991417576156\n",
      "-2.21884207628e-05 -2.21884207628e-05 0.000139120475577\n",
      "0.000198189765861 0.000198189765861 3.28352867471e-05\n",
      "0.00119282384596 0.00119282384596 0.0010626535163\n",
      "-0.000198533259143 -0.000198533259143 -0.000245796517956\n",
      "-0.00219194502089 -0.00219194502089 -0.0021130551788\n",
      "-0.00038977295089 -0.00038977295089 -0.000276339502674\n",
      "0.00267541689165 0.00267541689165 0.0027884940072\n",
      "-0.000122557902 -0.000122557902 -0.00024029334926\n",
      "0.000777866202309 0.000777866202309 0.000785304541492\n",
      "-0.000952766274672 -0.000952766274672 -0.00108430693876\n",
      "2.07646366614e-05 2.07646366614e-05 7.01311440383e-05\n",
      "1.84982217135e-05 1.84982217135e-05 -2.56754139842e-05\n",
      "0.00121406539769 0.00121406539769 0.00133101507501\n",
      "0.000229230365492 0.000229230365492 0.000189165435314\n",
      "0.000964054845979 0.000964054845979 0.00104692851723\n",
      "-0.000967178812812 -0.000967178812812 -0.000983602547415\n",
      "0.00149754889949 0.00149754889949 0.00144882123934\n",
      "0.000665357855235 0.000665357855235 0.000639737829665\n",
      "-0.000396733293759 -0.000396733293759 -0.000408613946325\n",
      "-0.00028362363939 -0.00028362363939 -0.000201814225835\n",
      "0.000371303722067 0.000371303722067 0.000388384167375\n",
      "-0.00118491239775 -0.00118491239775 -0.00101572644484\n",
      "0.00110179583782 0.00110179583782 0.00118737731141\n",
      "0.000994765576657 0.000994765576657 0.00103647976955\n",
      "-0.000970285461203 -0.000970285461203 -0.000863600292661\n",
      "-0.000303711642004 -0.000303711642004 -0.000290700515339\n",
      "-0.00196688039542 -0.00196688039542 -0.00198737530685\n",
      "0.00295223828721 0.00295223828721 0.00272696896678\n",
      "-0.00153635048102 -0.00153635048102 -0.00154051719818\n",
      "-0.00224915462714 -0.00224915462714 -0.00219136538243\n",
      "0.00113345303895 0.00113345303895 0.00112553089203\n",
      "0.000466835476312 0.000466835476312 0.000519186308971\n",
      "0.000356715174345 0.000356715174345 0.000165243105458\n",
      "-0.000258640671016 -0.000258640671016 -0.00034055241935\n",
      "-3.07306022188e-05 -3.07306022188e-05 -8.94928808268e-06\n",
      "0.00086298600948 0.00086298600948 0.000789526543874\n",
      "-0.000945861575826 -0.000945861575826 -0.000907088827928\n",
      "0.00123735216822 0.00123735216822 0.00110350659483\n",
      "-0.00161610215882 -0.00161610215882 -0.00169569961293\n",
      "-0.00307225077155 -0.00307225077155 -0.00303539802522\n",
      "0.00134968450783 0.00134968450783 0.00146872762517\n",
      "0.000569147824005 0.000569147824005 0.000631210913847\n",
      "-1.50367771913e-05 -1.50367771913e-05 4.73297196412e-05\n",
      "-0.00196257713008 -0.00196257713008 -0.00187962438384\n",
      "0.000290914506635 0.000290914506635 0.0004753711319\n",
      "0.00010786855835 0.00010786855835 5.18674825372e-05\n",
      "-0.000839660666387 -0.000839660666387 -0.000738102888594\n",
      "-0.00184672028157 -0.00184672028157 -0.00178503380216\n",
      "0.00277577564556 0.00277577564556 0.00286228072729\n",
      "-0.00178168161164 -0.00178168161164 -0.00180587215081\n",
      "-0.000566482557799 -0.000566482557799 -0.000548109286549\n",
      "0.00060320882037 0.00060320882037 0.000407462179726\n",
      "0.000329262391318 0.000329262391318 0.000193681466089\n",
      "-0.000178249351018 -0.000178249351018 -9.07010408322e-05\n",
      "0.000161350297623 0.000161350297623 8.50442131949e-05\n",
      "0.00018577517908 0.00018577517908 8.37032105884e-05\n",
      "-0.00079528432572 -0.00079528432572 -0.000920728186163\n",
      "0.000719767099939 0.000719767099939 0.000921158037564\n",
      "-0.00130637323884 -0.00130637323884 -0.00109456214119\n",
      "-0.00128499169863 -0.00128499169863 -0.00115243456627\n",
      "0.00141490406375 0.00141490406375 0.00141758741031\n",
      "0.00043253990088 0.00043253990088 0.000417743798684\n",
      "0.000950018837842 0.000950018837842 0.00102340444574\n",
      "-0.00137410520842 -0.00137410520842 -0.00161936394365\n",
      "-0.00194478214702 -0.00194478214702 -0.0017467424109\n",
      "-0.00170694931576 -0.00170694931576 -0.00175392048744\n",
      "0.00048045590563 0.00048045590563 0.000371922667423\n",
      "-0.00167036487507 -0.00167036487507 -0.00172065570772\n",
      "-0.00162419603087 -0.00162419603087 -0.00146586691667\n",
      "-0.00230196510296 -0.00230196510296 -0.00226978496561\n",
      "-0.000723544344574 -0.000723544344574 -0.000692453567343\n",
      "-0.00121200900966 -0.00121200900966 -0.00136577401647\n",
      "-0.00055063489487 -0.00055063489487 -0.000463701053218\n",
      "0.00254432332878 0.00254432332878 0.00259733979422\n",
      "-0.000867730693456 -0.000867730693456 -0.000954627035136\n",
      "-0.00175316655767 -0.00175316655767 -0.00175874189905\n",
      "-0.00100364278411 -0.00100364278411 -0.00100112722121\n",
      "-2.99562288911e-05 -2.99562288911e-05 -0.000154193773808\n",
      "0.00142548945995 0.00142548945995 0.00140160514907\n",
      "-0.000781982932642 -0.000781982932642 -0.00104619138287\n",
      "-0.0022405391108 -0.0022405391108 -0.0023136563361\n",
      "0.00181207222638 0.00181207222638 0.00185191963558\n",
      "0.00399034856026 0.00399034856026 0.00391367617336\n",
      "-0.00197596567503 -0.00197596567503 -0.00198785191271\n",
      "0.00039579878987 0.00039579878987 0.00043118803234\n",
      "-0.0060795190575 -0.0060795190575 -0.00592681709615\n",
      "0.000165189563482 0.000165189563482 0.000268309801508\n",
      "0.0013342963131 0.0013342963131 0.00114110317814\n",
      "-0.00284225337461 -0.00284225337461 -0.00291027518081\n",
      "-0.000278044698123 -0.000278044698123 -0.000177301158431\n",
      "0.000751312502322 0.000751312502322 0.000766385389923\n",
      "-0.0002071025639 -0.0002071025639 -0.00011776950197\n",
      "-0.00382272147773 -0.00382272147773 -0.00381617257854\n",
      "0.00151751207173 0.00151751207173 0.00154906416991\n",
      "0.00193240344595 0.00193240344595 0.00221070733485\n",
      "-0.00246937068052 -0.00246937068052 -0.00257233992989\n",
      "0.00255996823082 0.00255996823082 0.00254351323491\n",
      "0.000733832140264 0.000733832140264 0.000685695083683\n",
      "0.00411235054352 0.00411235054352 0.00398497150082\n",
      "-0.00361146953747 -0.00361146953747 -0.00365948960673\n",
      "-0.00296350659211 -0.00296350659211 -0.00287741563804\n",
      "-0.00284215973581 -0.00284215973581 -0.00274353090015\n",
      "0.000925119608562 0.000925119608562 0.000874636798063\n",
      "-0.00233889894385 -0.00233889894385 -0.00250248827834\n",
      "0.00283348438916 0.00283348438916 0.00284799798954\n",
      "-0.00223134115473 -0.00223134115473 -0.00224562013982\n",
      "0.00209214635565 0.00209214635565 0.00210661510997\n",
      "-0.000633650570939 -0.000633650570939 -0.000528562094621\n",
      "0.00200054499934 0.00200054499934 0.00197348548492\n",
      "0.000588063951826 0.000588063951826 0.000520752030469\n",
      "0.00186210866506 0.00186210866506 0.00186144075348\n",
      "-0.00242899652484 -0.00242899652484 -0.00232598816874\n",
      "0.00200289185346 0.00200289185346 0.00199936728312\n",
      "0.00257872459422 0.00257872459422 0.00276842950889\n",
      "-0.00254809823536 -0.00254809823536 -0.00279435873642\n",
      "0.000243416526045 0.000243416526045 0.000155586603586\n",
      "0.000474354585164 0.000474354585164 0.000456129175466\n",
      "-0.000422790713786 -0.000422790713786 -0.000539909396796\n",
      "8.33696624206e-05 8.33696624206e-05 0.000259147066833\n",
      "0.000818832931024 0.000818832931024 0.000785372366735\n",
      "-0.00161331866433 -0.00161331866433 -0.00190187124024\n",
      "-0.000788211165644 -0.000788211165644 -0.000870432243959\n",
      "-0.000277105145437 -0.000277105145437 -0.000234485056874\n",
      "-0.00103187762973 -0.00103187762973 -0.00112309116503\n",
      "0.000352540244535 0.000352540244535 0.00024209342256\n",
      "-0.00059129720475 -0.00059129720475 -0.000586129237755\n",
      "-0.000618018991915 -0.000618018991915 -0.000644022998587\n",
      "-0.00254948260051 -0.00254948260051 -0.00246332755486\n",
      "0.000116860021322 0.000116860021322 0.000103736751509\n",
      "0.00225162592688 0.00225162592688 0.00251913617774\n",
      "0.00208765981154 0.00208765981154 0.00207992321288\n",
      "-0.00168285089067 -0.00168285089067 -0.00152011077756\n",
      "-0.00259181777696 -0.00259181777696 -0.00270951168248\n",
      "0.00223270642157 0.00223270642157 0.00225879278644\n",
      "-0.000569918553789 -0.000569918553789 -0.000621230380921\n",
      "-0.000979317755756 -0.000979317755756 -0.00106501178334\n",
      "0.00110040387797 0.00110040387797 0.00102027086541\n",
      "0.00245343780032 0.00245343780032 0.00266170786974\n",
      "0.00148259210092 0.00148259210092 0.00172792501959\n",
      "-0.00179355199478 -0.00179355199478 -0.00176835740039\n",
      "0.00210177693242 0.00210177693242 0.00218154034985\n",
      "0.000711725577219 0.000711725577219 0.000748221337056\n",
      "0.000188264834555 0.000188264834555 0.000336767605909\n",
      "-0.000959546188809 -0.000959546188809 -0.00103029178382\n",
      "-0.0019656615198 -0.0019656615198 -0.00192798297221\n",
      "-0.00020777968667 -0.00020777968667 -0.000317072430741\n",
      "-5.37802381499e-05 -5.37802381499e-05 -0.00016712440189\n",
      "-0.00129485755412 -0.00129485755412 -0.00126608579223\n",
      "0.0010936079957 0.0010936079957 0.00120469779508\n",
      "0.00213490288936 0.00213490288936 0.00218398497338\n",
      "-0.00111745606654 -0.00111745606654 -0.00115163883839\n",
      "-0.000840088289879 -0.000840088289879 -0.000914329270574\n",
      "-0.00340379799604 -0.00340379799604 -0.00331475090887\n",
      "0.00129892576241 0.00129892576241 0.00129817683588\n",
      "-0.000971405787002 -0.000971405787002 -0.000700135471533\n",
      "0.000269523471339 0.000269523471339 0.000316313803924\n",
      "0.00510065631383 0.00510065631383 0.00514757655471\n",
      "-0.00157537980823 -0.00157537980823 -0.0015589330946\n",
      "0.000137576979131 0.000137576979131 0.000246435019025\n",
      "0.000308792334056 0.000308792334056 0.000125167327261\n",
      "-0.00193514217997 -0.00193514217997 -0.00179766401514\n",
      "-0.0012628133377 -0.0012628133377 -0.00123764036024\n",
      "-0.000674914024803 -0.000674914024803 -0.000740516086691\n",
      "0.000825100050306 0.000825100050306 0.000857827527072\n",
      "-0.000218091931737 -0.000218091931737 -0.00019315697661\n",
      "-0.00228063450825 -0.00228063450825 -0.00243719904983\n",
      "0.00220750366553 0.00220750366553 0.0022247424157\n",
      "-0.00202486363132 -0.00202486363132 -0.00190830973399\n",
      "-0.00165632439439 -0.00165632439439 -0.0016603868124\n",
      "0.00137410872651 0.00137410872651 0.00141415576778\n",
      "0.000289167982214 0.000289167982214 0.000311971807324\n",
      "-0.00211947205043 -0.00211947205043 -0.00213298308693\n",
      "-0.000214535274458 -0.000214535274458 -8.94012908481e-05\n",
      "-0.000356678552665 -0.000356678552665 -0.000280302534682\n",
      "0.0013078514518 0.0013078514518 0.00142906728627\n",
      "0.00134761881341 0.00134761881341 0.00147501798364\n",
      "-0.000139153275035 -0.000139153275035 -8.56315273101e-06\n",
      "0.00303550174534 0.00303550174534 0.0029397867717\n",
      "0.000979036431519 0.000979036431519 0.00105257029109\n",
      "0.00224002028003 0.00224002028003 0.00222417550682\n",
      "0.000519077726196 0.000519077726196 0.000458961496684\n",
      "0.00287455191246 0.00287455191246 0.0029594031326\n",
      "0.000391868056791 0.000391868056791 0.000293236356683\n",
      "-0.00162979847136 -0.00162979847136 -0.00164773477187\n",
      "0.00115481047914 0.00115481047914 0.0010188258197\n",
      "-0.000861039434678 -0.000861039434678 -0.000682585401576\n",
      "-0.000568184838183 -0.000568184838183 -0.000463595305714\n",
      "0.0019839127382 0.0019839127382 0.00199357393303\n",
      "-0.00135144063163 -0.00135144063163 -0.00136482172788\n",
      "-0.000802353409496 -0.000802353409496 -0.000829337613241\n",
      "0.000607643510261 0.000607643510261 0.000487225919158\n",
      "-0.00228334842837 -0.00228334842837 -0.00219213762421\n",
      "0.00207264904741 0.00207264904741 0.00206211285576\n",
      "-0.00118039002245 -0.00118039002245 -0.00109805231011\n",
      "0.00108178251536 0.00108178251536 0.00117036670622\n",
      "-0.000169131468012 -0.000169131468012 -0.000236245223298\n",
      "-0.000959039905526 -0.000959039905526 -0.000818229564517\n",
      "0.00312487601238 0.00312487601238 0.00318094617338\n",
      "-0.00144946368095 -0.00144946368095 -0.00138039537017\n",
      "0.00248448152125 0.00248448152125 0.00244761695482\n",
      "0.00250798837274 0.00250798837274 0.00251662671038\n",
      "-0.00124131630866 -0.00124131630866 -0.00108148617944\n",
      "-0.00114396807902 -0.00114396807902 -0.00126277433539\n",
      "0.00222516766643 0.00222516766643 0.00223512795974\n",
      "-0.00072290637481 -0.00072290637481 -0.000819881874202\n",
      "-0.00195461329009 -0.00195461329009 -0.00183078632756\n",
      "0.000267198755726 0.000267198755726 0.00037721982237\n",
      "0.000394454083437 0.000394454083437 0.000423039965423\n",
      "0.000828041416994 0.000828041416994 0.000812551786303\n",
      "-0.00114077633125 -0.00114077633125 -0.00116986099892\n",
      "-0.00167394012026 -0.00167394012026 -0.0017949023279\n",
      "0.000465323862303 0.000465323862303 0.000678470018338\n",
      "0.000739960687678 0.000739960687678 0.000815886915154\n",
      "-0.00196534719782 -0.00196534719782 -0.00194458309054\n",
      "-0.00240614074458 -0.00240614074458 -0.00251757921801\n",
      "0.00105029748243 0.00105029748243 0.00086138865815\n",
      "-0.000939460039913 -0.000939460039913 -0.000942283056949\n",
      "0.000578168956395 0.000578168956395 0.000572391757669\n",
      "-0.00162016780225 -0.00162016780225 -0.00169129022135\n",
      "-0.000804121270746 -0.000804121270746 -0.000934777784195\n",
      "0.00181648374781 0.00181648374781 0.00192216456153\n",
      "-0.00334106954631 -0.00334106954631 -0.0033951830163\n",
      "-0.000511253551113 -0.000511253551113 -0.000536135089058\n",
      "-0.00121951136851 -0.00121951136851 -0.00129972190797\n",
      "-0.00118690362213 -0.00118690362213 -0.00126212542284\n",
      "-0.000452818386988 -0.000452818386988 -0.00052675893609\n",
      "-0.00054814835304 -0.00054814835304 -0.000493761862493\n",
      "0.0015657536503 0.0015657536503 0.00141762069074\n",
      "0.00269210222411 0.00269210222411 0.00262018940485\n",
      "0.00325424673755 0.00325424673755 0.00322664069061\n",
      "0.00183911076724 0.00183911076724 0.00189299525213\n",
      "-9.36270704852e-06 -9.36270704852e-06 -3.70002217132e-05\n",
      "0.000351710337859 0.000351710337859 0.000219072008522\n",
      "0.000121021595922 0.000121021595922 0.000264278128023\n",
      "-0.000876887747293 -0.000876887747293 -0.00106340654\n",
      "-0.00276508931718 -0.00276508931718 -0.00291640771331\n",
      "0.00122385053301 0.00122385053301 0.00138299341535\n",
      "0.00229791984243 0.00229791984243 0.00233056154734\n",
      "0.00232151793709 0.00232151793709 0.00235303969573\n",
      "0.000142012947842 0.000142012947842 0.000214881324669\n",
      "-0.000274753548833 -0.000274753548833 -0.00040075055476\n",
      "-0.00391424802087 -0.00391424802087 -0.00393402818936\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "np_answer = np.dot(T_matrix,T_tran)[0,:]\n",
    "np_direct = [0,:]\n",
    "dot_first_row = []\n",
    "for i in range(300):\n",
    "    print(np_answer[i], np_direct[i], np.dot(T_matrix[0,:],T_matrix[:,i]))\n",
    "#     print(dot_first_row[i] - np_answer[i])\n",
    "\n",
    "print(dot_first_row)\n",
    "\n",
    "# print(T_matrix[0,:].tolist()[:10])\n",
    "# print(T_tran[:,0].tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0037940085339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  3.79400853e-03,  -3.99833613e-03,   3.74123077e-03, ...,\n",
       "          2.14881325e-04,  -4.00750555e-04,  -3.93402819e-03],\n",
       "       [ -3.96567107e-03,   5.99035875e-03,  -4.74668324e-03, ...,\n",
       "         -4.68861535e-04,   4.52156872e-04,   5.13800372e-03],\n",
       "       [  3.67768717e-03,  -4.72474476e-03,   5.01318668e-03, ...,\n",
       "          5.54791415e-05,  -4.36420889e-04,  -4.55180444e-03],\n",
       "       ..., \n",
       "       [  1.56950907e-04,  -3.54034046e-04,   1.35169133e-05, ...,\n",
       "          9.77759589e-04,   9.15033589e-05,   2.99635849e-06],\n",
       "       [ -2.66717928e-04,   2.89106130e-04,  -2.99902717e-04, ...,\n",
       "          1.52613504e-04,   7.74957173e-04,   4.36232387e-04],\n",
       "       [ -3.82118356e-03,   5.00802397e-03,  -4.47773544e-03, ...,\n",
       "         -1.40436752e-04,   5.36197672e-04,   5.72363250e-03]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.62798872e-02,  -8.00443720e-03,   9.06144828e-03, ...,\n",
       "          4.51286905e-04,  -6.37024525e-04,  -6.43303106e-03],\n",
       "       [ -7.71387713e-03,   3.17478180e-02,  -1.03924386e-02, ...,\n",
       "         -3.13700526e-03,   1.11302815e-03,   9.44260973e-03],\n",
       "       [  8.97303317e-03,  -1.00596156e-02,   3.05041317e-02, ...,\n",
       "          5.88151684e-04,   6.44203828e-06,  -7.75917433e-03],\n",
       "       ..., \n",
       "       [  8.34789593e-04,  -3.14916088e-03,   6.72287075e-04, ...,\n",
       "          1.96522009e-02,  -1.65478152e-04,   1.01957284e-03],\n",
       "       [  1.29190652e-04,   3.62422550e-04,   2.75136787e-04, ...,\n",
       "          1.05115771e-03,   1.94369927e-02,   1.32160319e-03],\n",
       "       [ -6.42255787e-03,   8.82536173e-03,  -7.61175994e-03, ...,\n",
       "         -4.40414988e-05,   1.17071450e-03,   2.85430402e-02]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.026279887184500694, -0.008004437200725079, 0.009061448276042938, 0.012618507258594036, -0.005415447521954775, -0.008686361834406853, 0.008724816143512726, 0.0036843381822109222, -0.003325438592582941, -0.005768531933426857]\n",
      "[0.026279887184500694, -0.007713877130299807, 0.008973033167421818, 0.012088065035641193, -0.0052625639364123344, -0.009280218742787838, 0.009108894504606724, 0.003987328615039587, -0.0037526364903897047, -0.0068390341475605965]\n"
     ]
    }
   ],
   "source": [
    "T_tran = T_matrix.T\n",
    "T_cov = np.dot(T_matrix,T_tran)\n",
    "print(np.dot(T_matrix[0],T_tran[0]))\n",
    "display(np.dot(T_matrix,T_matrix))\n",
    "\n",
    "display(T_matrix)\n",
    "print(T_matrix[0].tolist()[:10])\n",
    "print(T_tran[:][0].tolist()[:10])\n",
    "# display(T_tran)\n",
    "# display(T_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?np.set_printoptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>...</th>\n",
       "      <th>200</th>\n",
       "      <th>201</th>\n",
       "      <th>202</th>\n",
       "      <th>203</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "      <th>214</th>\n",
       "      <th>215</th>\n",
       "      <th>216</th>\n",
       "      <th>217</th>\n",
       "      <th>218</th>\n",
       "      <th>219</th>\n",
       "      <th>220</th>\n",
       "      <th>221</th>\n",
       "      <th>222</th>\n",
       "      <th>223</th>\n",
       "      <th>224</th>\n",
       "      <th>225</th>\n",
       "      <th>226</th>\n",
       "      <th>227</th>\n",
       "      <th>228</th>\n",
       "      <th>229</th>\n",
       "      <th>230</th>\n",
       "      <th>231</th>\n",
       "      <th>232</th>\n",
       "      <th>233</th>\n",
       "      <th>234</th>\n",
       "      <th>235</th>\n",
       "      <th>236</th>\n",
       "      <th>237</th>\n",
       "      <th>238</th>\n",
       "      <th>239</th>\n",
       "      <th>240</th>\n",
       "      <th>241</th>\n",
       "      <th>242</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "      <th>256</th>\n",
       "      <th>257</th>\n",
       "      <th>258</th>\n",
       "      <th>259</th>\n",
       "      <th>260</th>\n",
       "      <th>261</th>\n",
       "      <th>262</th>\n",
       "      <th>263</th>\n",
       "      <th>264</th>\n",
       "      <th>265</th>\n",
       "      <th>266</th>\n",
       "      <th>267</th>\n",
       "      <th>268</th>\n",
       "      <th>269</th>\n",
       "      <th>270</th>\n",
       "      <th>271</th>\n",
       "      <th>272</th>\n",
       "      <th>273</th>\n",
       "      <th>274</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "      <th>285</th>\n",
       "      <th>286</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026280</td>\n",
       "      <td>-0.008004</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.012619</td>\n",
       "      <td>-0.005415</td>\n",
       "      <td>-0.008686</td>\n",
       "      <td>0.008725</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.005769</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.001629</td>\n",
       "      <td>-0.002036</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>0.002653</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>-0.004112</td>\n",
       "      <td>0.003440</td>\n",
       "      <td>-0.001573</td>\n",
       "      <td>-0.003114</td>\n",
       "      <td>-0.002909</td>\n",
       "      <td>-0.001654</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.005597</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.001567</td>\n",
       "      <td>0.006766</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>-0.005909</td>\n",
       "      <td>-0.004805</td>\n",
       "      <td>-0.001347</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.003756</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.004184</td>\n",
       "      <td>-0.004590</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>-0.006687</td>\n",
       "      <td>-0.001861</td>\n",
       "      <td>0.005790</td>\n",
       "      <td>-0.002028</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>-0.001408</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.002651</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.005070</td>\n",
       "      <td>-0.000204</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>-0.001615</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>-0.002736</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.003872</td>\n",
       "      <td>-0.000343</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>-0.003599</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>-0.002531</td>\n",
       "      <td>-0.002957</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>-0.002501</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>-0.001152</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000431</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.004429</td>\n",
       "      <td>-0.001156</td>\n",
       "      <td>-0.001897</td>\n",
       "      <td>-0.001739</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>-0.001684</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.000647</td>\n",
       "      <td>-0.000990</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>-0.003440</td>\n",
       "      <td>-0.001535</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.000749</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>-0.001907</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>-0.005381</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>-0.004245</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>-0.002949</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.004975</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>-0.004034</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>-0.003017</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>-0.001625</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.004509</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>-0.001226</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>-0.001829</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>-0.002525</td>\n",
       "      <td>0.003969</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>-0.001154</td>\n",
       "      <td>-0.000780</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.003140</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>-0.002471</td>\n",
       "      <td>-0.003521</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>-0.004090</td>\n",
       "      <td>-0.003652</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>-0.001948</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>-0.001586</td>\n",
       "      <td>-0.001894</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>-0.005740</td>\n",
       "      <td>-0.001457</td>\n",
       "      <td>-0.001671</td>\n",
       "      <td>-0.002629</td>\n",
       "      <td>-0.001670</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.004193</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.001459</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>-0.003020</td>\n",
       "      <td>-0.003659</td>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.003322</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.006433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007714</td>\n",
       "      <td>0.031748</td>\n",
       "      <td>-0.010392</td>\n",
       "      <td>-0.012305</td>\n",
       "      <td>0.009108</td>\n",
       "      <td>0.011916</td>\n",
       "      <td>-0.007532</td>\n",
       "      <td>-0.005184</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.006496</td>\n",
       "      <td>-0.003059</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.002947</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>-0.004319</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.004014</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.008692</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>0.008842</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>-0.006270</td>\n",
       "      <td>-0.007498</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>-0.003850</td>\n",
       "      <td>-0.001510</td>\n",
       "      <td>-0.004352</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.007402</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>-0.008106</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>-0.000440</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>-0.003819</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>0.002922</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.002296</td>\n",
       "      <td>-0.003759</td>\n",
       "      <td>-0.005017</td>\n",
       "      <td>-0.003030</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.004471</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>0.005101</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>-0.006111</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>-0.004686</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.002369</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>-0.004118</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>-0.003553</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>-0.001112</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>-0.007461</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.002242</td>\n",
       "      <td>-0.001713</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>-0.001925</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>-0.005201</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.005423</td>\n",
       "      <td>-0.002046</td>\n",
       "      <td>-0.000673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>-0.003429</td>\n",
       "      <td>-0.004720</td>\n",
       "      <td>0.003111</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>-0.005800</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>-0.007429</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.003172</td>\n",
       "      <td>-0.004781</td>\n",
       "      <td>-0.000804</td>\n",
       "      <td>0.003323</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.004036</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.005767</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>-0.007044</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>-0.002026</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>-0.005978</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>-0.001730</td>\n",
       "      <td>-0.007466</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>-0.002310</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>-0.000374</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>-0.003890</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>-0.003224</td>\n",
       "      <td>-0.002985</td>\n",
       "      <td>0.004790</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>-0.001942</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.006913</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.001520</td>\n",
       "      <td>-0.003888</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>-0.007732</td>\n",
       "      <td>-0.003013</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>-0.005866</td>\n",
       "      <td>-0.005291</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.009443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008973</td>\n",
       "      <td>-0.010060</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>0.006090</td>\n",
       "      <td>0.003015</td>\n",
       "      <td>-0.003181</td>\n",
       "      <td>-0.007588</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>-0.002809</td>\n",
       "      <td>-0.003135</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>-0.000859</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>-0.006922</td>\n",
       "      <td>0.004210</td>\n",
       "      <td>-0.003514</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>-0.005710</td>\n",
       "      <td>-0.000394</td>\n",
       "      <td>-0.001425</td>\n",
       "      <td>-0.000699</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>-0.007845</td>\n",
       "      <td>-0.006219</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>0.005896</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>-0.004880</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>-0.008598</td>\n",
       "      <td>-0.002551</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>-0.001493</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>-0.003466</td>\n",
       "      <td>-0.000688</td>\n",
       "      <td>-0.002165</td>\n",
       "      <td>-0.003558</td>\n",
       "      <td>-0.001682</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.005340</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.001152</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>-0.001190</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>-0.002926</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>-0.002774</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.002407</td>\n",
       "      <td>-0.001534</td>\n",
       "      <td>-0.000239</td>\n",
       "      <td>-0.002027</td>\n",
       "      <td>0.007273</td>\n",
       "      <td>-0.004202</td>\n",
       "      <td>-0.004670</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.001312</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>-0.001023</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>-0.004939</td>\n",
       "      <td>-0.006969</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>-0.001813</td>\n",
       "      <td>-0.004207</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>-0.000327</td>\n",
       "      <td>-0.001621</td>\n",
       "      <td>0.002477</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>-0.002373</td>\n",
       "      <td>-0.003191</td>\n",
       "      <td>-0.008072</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>-0.004064</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>-0.002982</td>\n",
       "      <td>-0.002565</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>-0.000614</td>\n",
       "      <td>-0.005343</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>-0.002944</td>\n",
       "      <td>-0.003785</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>-0.003524</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>-0.000174</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.002532</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>-0.001487</td>\n",
       "      <td>-0.002336</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>0.004213</td>\n",
       "      <td>-0.001465</td>\n",
       "      <td>-0.002851</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>-0.004204</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>-0.004156</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>-0.002560</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>-0.003326</td>\n",
       "      <td>0.004705</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>-0.001368</td>\n",
       "      <td>-0.003854</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>-0.001267</td>\n",
       "      <td>-0.003761</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>0.002421</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.005842</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>-0.004669</td>\n",
       "      <td>-0.004021</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>-0.002898</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>-0.006383</td>\n",
       "      <td>-0.001492</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>-0.006580</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-0.004500</td>\n",
       "      <td>-0.001469</td>\n",
       "      <td>-0.001158</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>0.003210</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>-0.002533</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>-0.000764</td>\n",
       "      <td>-0.001526</td>\n",
       "      <td>-0.005170</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.007759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.012088</td>\n",
       "      <td>-0.012271</td>\n",
       "      <td>0.015024</td>\n",
       "      <td>0.041155</td>\n",
       "      <td>-0.010766</td>\n",
       "      <td>-0.013844</td>\n",
       "      <td>0.011766</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>-0.003505</td>\n",
       "      <td>-0.009180</td>\n",
       "      <td>-0.001073</td>\n",
       "      <td>-0.002930</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.004932</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>-0.009088</td>\n",
       "      <td>0.004991</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.004301</td>\n",
       "      <td>-0.005110</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>-0.000841</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.009509</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>-0.003716</td>\n",
       "      <td>0.009401</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>-0.007460</td>\n",
       "      <td>-0.007721</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.006925</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.003235</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>-0.002839</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.005610</td>\n",
       "      <td>-0.012999</td>\n",
       "      <td>-0.002945</td>\n",
       "      <td>0.008515</td>\n",
       "      <td>-0.001330</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>-0.004450</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>-0.004091</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>-0.004035</td>\n",
       "      <td>-0.003320</td>\n",
       "      <td>-0.002771</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.004606</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>-0.000690</td>\n",
       "      <td>-0.005746</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>-0.002113</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>-0.000825</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.001016</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>-0.002924</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>-0.005398</td>\n",
       "      <td>0.009012</td>\n",
       "      <td>-0.003501</td>\n",
       "      <td>-0.004989</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.000313</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>-0.000531</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>-0.005696</td>\n",
       "      <td>-0.005551</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>-0.000719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>-0.003153</td>\n",
       "      <td>-0.004415</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>-0.003080</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>-0.001817</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>-0.011145</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>-0.002473</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.012549</td>\n",
       "      <td>-0.003359</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>-0.004495</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>-0.002929</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.006909</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>-0.004069</td>\n",
       "      <td>-0.005004</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>-0.007051</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.007607</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.004660</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>-0.003096</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>-0.005901</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>-0.005083</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>-0.005977</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>-0.006528</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>-0.003654</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>-0.001845</td>\n",
       "      <td>-0.003697</td>\n",
       "      <td>0.004432</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>-0.005279</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>-0.002119</td>\n",
       "      <td>-0.007686</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>-0.005267</td>\n",
       "      <td>-0.006276</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.003338</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.004876</td>\n",
       "      <td>-0.001202</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>-0.010689</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-0.002578</td>\n",
       "      <td>-0.003413</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>-0.001682</td>\n",
       "      <td>-0.001474</td>\n",
       "      <td>-0.006860</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.007494</td>\n",
       "      <td>0.005744</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.002888</td>\n",
       "      <td>-0.010536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005263</td>\n",
       "      <td>0.008820</td>\n",
       "      <td>-0.005924</td>\n",
       "      <td>-0.010617</td>\n",
       "      <td>0.029115</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>-0.001456</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.003837</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>-0.004151</td>\n",
       "      <td>0.005421</td>\n",
       "      <td>-0.003345</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>-0.000694</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.001429</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>-0.004837</td>\n",
       "      <td>-0.005424</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>-0.001686</td>\n",
       "      <td>-0.004305</td>\n",
       "      <td>-0.005190</td>\n",
       "      <td>-0.002029</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>-0.002130</td>\n",
       "      <td>-0.004201</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>-0.001719</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>-0.003328</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>-0.002872</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>-0.003103</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>-0.002734</td>\n",
       "      <td>-0.002068</td>\n",
       "      <td>-0.004790</td>\n",
       "      <td>-0.000285</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>-0.004649</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>-0.002023</td>\n",
       "      <td>-0.001014</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>0.001349</td>\n",
       "      <td>-0.000762</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>-0.002504</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>-0.002378</td>\n",
       "      <td>0.001075</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>-0.003498</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>-0.006142</td>\n",
       "      <td>0.003170</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>-0.000697</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>-0.004318</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>-0.002633</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.003252</td>\n",
       "      <td>-0.002213</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>-0.002866</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>-0.010025</td>\n",
       "      <td>0.002354</td>\n",
       "      <td>-0.002240</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.004401</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>-0.001941</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>-0.004643</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>-0.002834</td>\n",
       "      <td>-0.000655</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.001525</td>\n",
       "      <td>-0.001259</td>\n",
       "      <td>-0.001737</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>-0.005206</td>\n",
       "      <td>-0.002326</td>\n",
       "      <td>-0.003194</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>-0.006786</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>-0.001076</td>\n",
       "      <td>-0.003187</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.002998</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>-0.002048</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>-0.006123</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>-0.002951</td>\n",
       "      <td>-0.003802</td>\n",
       "      <td>0.003183</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.002040</td>\n",
       "      <td>0.003376</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.004725</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>-0.003601</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>-0.000259</td>\n",
       "      <td>-0.000626</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.004186</td>\n",
       "      <td>-0.000203</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>-0.001406</td>\n",
       "      <td>-0.004191</td>\n",
       "      <td>-0.003468</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.008381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.026280 -0.008004  0.009061  0.012619 -0.005415 -0.008686  0.008725   \n",
       "1 -0.007714  0.031748 -0.010392 -0.012305  0.009108  0.011916 -0.007532   \n",
       "2  0.008973 -0.010060  0.030504  0.014472 -0.006473 -0.010670  0.006090   \n",
       "3  0.012088 -0.012271  0.015024  0.041155 -0.010766 -0.013844  0.011766   \n",
       "4 -0.005263  0.008820 -0.005924 -0.010617  0.029115  0.009380 -0.007132   \n",
       "\n",
       "        7         8         9         10        11        12        13   \\\n",
       "0  0.003684 -0.003325 -0.005769 -0.000817 -0.001629 -0.002036  0.000980   \n",
       "1 -0.005184  0.004324  0.006496 -0.003059  0.002587  0.002850 -0.001647   \n",
       "2  0.003015 -0.003181 -0.007588  0.001565 -0.002809 -0.003135  0.001605   \n",
       "3  0.000982 -0.003505 -0.009180 -0.001073 -0.002930 -0.003866  0.004932   \n",
       "4 -0.000059  0.001184  0.006593 -0.001456  0.001233  0.003861 -0.001215   \n",
       "\n",
       "        14        15        16        17        18        19        20   \\\n",
       "0  0.002653 -0.000290  0.003938 -0.004112  0.003440 -0.001573 -0.003114   \n",
       "1 -0.002947  0.002204 -0.004006  0.008060 -0.004319  0.002852  0.002112   \n",
       "2  0.002630 -0.000859  0.005250 -0.006922  0.004210 -0.003514 -0.001346   \n",
       "3  0.006947  0.001145  0.007360 -0.009088  0.004991 -0.004035 -0.004301   \n",
       "4 -0.003837  0.000759 -0.004151  0.005421 -0.003345  0.002406  0.002346   \n",
       "\n",
       "        21        22        23        24        25        26        27   \\\n",
       "0 -0.002909 -0.001654 -0.000874 -0.000060  0.005597 -0.000463 -0.001567   \n",
       "1  0.005594 -0.000842  0.001690 -0.000260 -0.004397 -0.004014  0.000977   \n",
       "2 -0.005710 -0.000394 -0.001425 -0.000699  0.004740  0.003743 -0.001963   \n",
       "3 -0.005110  0.000406 -0.000841  0.000565  0.009509  0.000449 -0.003716   \n",
       "4  0.005678 -0.000694  0.001849  0.000586 -0.005188 -0.001429  0.001655   \n",
       "\n",
       "        28        29        30        31        32        33        34   \\\n",
       "0  0.006766  0.006126 -0.005909 -0.004805 -0.001347  0.005537  0.003756   \n",
       "1 -0.008692 -0.007088  0.008842  0.004742 -0.000047 -0.006270 -0.007498   \n",
       "2  0.008930  0.005329 -0.007845 -0.006219 -0.000499  0.003678  0.005896   \n",
       "3  0.009401  0.005983 -0.007460 -0.007721 -0.001028  0.006212  0.006925   \n",
       "4 -0.004837 -0.005424  0.004596  0.001937 -0.001686 -0.004305 -0.005190   \n",
       "\n",
       "        35        36        37        38        39        40        41   \\\n",
       "0  0.002721  0.003895  0.002470  0.004184 -0.004590  0.000956  0.000143   \n",
       "1 -0.003348 -0.003850 -0.001510 -0.004352  0.006044 -0.001624 -0.000057   \n",
       "2  0.002589  0.002950  0.003697  0.000525 -0.004880  0.001664  0.004049   \n",
       "3  0.002406  0.003235  0.005158  0.005773 -0.002839  0.003964  0.005501   \n",
       "4 -0.002029  0.001040 -0.002130 -0.004201  0.001746 -0.001719 -0.000720   \n",
       "\n",
       "        42        43        44        45        46        47        48   \\\n",
       "0  0.004943 -0.006687 -0.001861  0.005790 -0.002028  0.003358 -0.001408   \n",
       "1 -0.007402  0.007801  0.001897 -0.008106  0.001119 -0.000440  0.002499   \n",
       "2  0.004756 -0.008598 -0.002551  0.004827 -0.001493  0.001752 -0.001263   \n",
       "3  0.005610 -0.012999 -0.002945  0.008515 -0.001330  0.000449 -0.004450   \n",
       "4 -0.003328  0.004299  0.001203 -0.002872  0.000424 -0.000034  0.001370   \n",
       "\n",
       "        49        50        51        52        53        54        55   \\\n",
       "0  0.004210 -0.003539 -0.001020 -0.000208 -0.002060 -0.000859  0.002053   \n",
       "1 -0.003819  0.005058  0.001709  0.002922  0.002386  0.002296 -0.003759   \n",
       "2  0.002125 -0.003466 -0.000688 -0.002165 -0.003558 -0.001682  0.001880   \n",
       "3  0.006653 -0.004091  0.000208 -0.004035 -0.003320 -0.002771  0.000396   \n",
       "4 -0.003103  0.002731  0.000885  0.003639  0.001346  0.002668 -0.002734   \n",
       "\n",
       "        56        57        58        59        60        61        62   \\\n",
       "0  0.004026  0.001058  0.000715  0.000500  0.002651 -0.001065 -0.005070   \n",
       "1 -0.005017 -0.003030 -0.000109 -0.000054 -0.004471 -0.000454  0.005101   \n",
       "2  0.004827  0.003003  0.000511 -0.000904  0.002554 -0.003325 -0.005340   \n",
       "3  0.004606  0.005559  0.001181 -0.001142  0.003037 -0.000690 -0.005746   \n",
       "4 -0.002068 -0.004790 -0.000285  0.002091 -0.004649 -0.000161  0.003648   \n",
       "\n",
       "        63        64        65        66        67        68        69   \\\n",
       "0 -0.000204  0.006096 -0.001615  0.001544 -0.000894  0.000560  0.000208   \n",
       "1  0.000593 -0.006111  0.002130 -0.004686  0.001869 -0.001151  0.000165   \n",
       "2  0.000609  0.005103 -0.000665  0.001828 -0.001152 -0.000541  0.000333   \n",
       "3  0.001277  0.006372 -0.000719  0.001242 -0.002113 -0.000874 -0.002792   \n",
       "4 -0.000029 -0.003947 -0.002023 -0.001014  0.000689 -0.001183  0.001349   \n",
       "\n",
       "        70        71        72        73        74        75        76   \\\n",
       "0  0.004445  0.000911  0.000829 -0.000285  0.002069  0.002130  0.000762   \n",
       "1 -0.002369  0.000432 -0.004118  0.001388 -0.000027 -0.003553 -0.000374   \n",
       "2  0.003231 -0.001190  0.003739 -0.002926  0.002709  0.000487 -0.000315   \n",
       "3  0.003884 -0.000825  0.003599 -0.001185  0.005286 -0.000201 -0.000465   \n",
       "4 -0.000762  0.000688 -0.002504  0.000593 -0.000347 -0.002378  0.001075   \n",
       "\n",
       "        77        78        79        80        81        82        83   \\\n",
       "0 -0.000789  0.000322 -0.002736  0.002274  0.003872 -0.000343  0.000267   \n",
       "1  0.000457 -0.001720  0.001960 -0.001112 -0.004988  0.002567  0.000237   \n",
       "2  0.000707 -0.000435 -0.002774  0.000285  0.002407 -0.001534 -0.000239   \n",
       "3 -0.001016  0.003050 -0.003793  0.003167  0.001321 -0.002924  0.000390   \n",
       "4  0.000390 -0.003498 -0.000781 -0.002079 -0.000441  0.000243  0.000614   \n",
       "\n",
       "        84        85        86        87        88        89        90   \\\n",
       "0 -0.003599  0.003444 -0.002531 -0.002957  0.002698  0.001191  0.001580   \n",
       "1  0.002094 -0.007461  0.005505  0.004316 -0.000295 -0.002242 -0.001713   \n",
       "2 -0.002027  0.007273 -0.004202 -0.004670  0.002727  0.002628  0.001312   \n",
       "3 -0.005398  0.009012 -0.003501 -0.004989  0.004805 -0.001365  0.000299   \n",
       "4  0.001846 -0.006142  0.003170  0.002044 -0.000697 -0.000535  0.001119   \n",
       "\n",
       "        91        92        93        94        95        96        97   \\\n",
       "0 -0.001202  0.000481  0.002843 -0.002501  0.002963 -0.001152 -0.004856   \n",
       "1  0.000191  0.001275 -0.001925  0.002361 -0.005201  0.004647  0.005423   \n",
       "2  0.000848  0.000359 -0.001023 -0.000658  0.002837 -0.004939 -0.006969   \n",
       "3 -0.000313 -0.000462 -0.000269 -0.000531  0.004473 -0.005696 -0.005551   \n",
       "4  0.001054  0.000384  0.000109  0.001405 -0.004318  0.004760  0.004909   \n",
       "\n",
       "        98        99     ...          200       201       202       203  \\\n",
       "0  0.002194  0.002001    ...    -0.000431 -0.000013 -0.004429 -0.001156   \n",
       "1 -0.002046 -0.000673    ...     0.001301  0.000919  0.003035  0.003439   \n",
       "2  0.002039  0.001874    ...     0.001698 -0.001813 -0.004207 -0.000088   \n",
       "3  0.004389 -0.000719    ...     0.001850 -0.003153 -0.004415  0.001171   \n",
       "4 -0.002633 -0.000359    ...     0.000464  0.000579  0.001728  0.000188   \n",
       "\n",
       "        204       205       206       207       208       209       210  \\\n",
       "0 -0.001897 -0.001739  0.004033  0.002368 -0.001684  0.000101 -0.003597   \n",
       "1  0.002267  0.002706 -0.003429 -0.004720  0.003111  0.000927  0.007936   \n",
       "2 -0.000327 -0.001621  0.002477  0.003446 -0.002373 -0.003191 -0.008072   \n",
       "3 -0.000532 -0.003080  0.003893  0.003471 -0.001817 -0.002367 -0.011145   \n",
       "4  0.001236 -0.000234 -0.003252 -0.002213  0.000718  0.001218  0.007080   \n",
       "\n",
       "        211       212       213       214       215       216       217  \\\n",
       "0  0.002648 -0.000647 -0.000990  0.007196 -0.003440 -0.001535 -0.000305   \n",
       "1 -0.005800  0.001613  0.000853 -0.011159  0.003716  0.000750  0.000061   \n",
       "2  0.001578 -0.001011 -0.000073  0.009089 -0.004064  0.002209 -0.000124   \n",
       "3  0.004774 -0.002473  0.000238  0.012549 -0.003359  0.002709 -0.002421   \n",
       "4 -0.002866  0.000485 -0.001395 -0.010025  0.002354 -0.002240  0.002242   \n",
       "\n",
       "        218       219       220       221       222       223       224  \\\n",
       "0 -0.000749 -0.002352 -0.001907  0.002293 -0.000242 -0.005381  0.004128   \n",
       "1  0.003889  0.002127  0.002441 -0.002929  0.002101  0.004701 -0.007429   \n",
       "2 -0.002982 -0.002565 -0.001185  0.001188 -0.000614 -0.005343  0.003543   \n",
       "3 -0.004495 -0.003468 -0.002929  0.001680 -0.000470 -0.006909  0.004150   \n",
       "4  0.003714  0.004401  0.002606 -0.001941  0.000761  0.004157 -0.004643   \n",
       "\n",
       "        225       226       227       228       229       230       231  \\\n",
       "0 -0.004245 -0.004390  0.003040 -0.000416 -0.002949  0.000271  0.000124   \n",
       "1  0.004515  0.003172 -0.004781 -0.000804  0.003323 -0.000385  0.000262   \n",
       "2 -0.002944 -0.003785  0.001028 -0.000782 -0.003524  0.000444 -0.000174   \n",
       "3 -0.004069 -0.005004  0.004372  0.000312 -0.007051  0.002942  0.000080   \n",
       "4  0.003202  0.001462 -0.002834 -0.000655  0.002769  0.001322  0.001525   \n",
       "\n",
       "        232       233       234       235       236       237       238  \\\n",
       "0  0.001080  0.003667  0.000445  0.004975 -0.000217  0.003448  0.001530   \n",
       "1  0.000190 -0.004036  0.000033 -0.005767 -0.000454 -0.005484 -0.000227   \n",
       "2  0.002176  0.002532  0.001365  0.004897  0.000828  0.005275  0.001081   \n",
       "3  0.003696  0.005099 -0.000217  0.005789  0.002025  0.006029  0.004255   \n",
       "4 -0.001259 -0.001737  0.000080 -0.005206 -0.002326 -0.003194  0.000720   \n",
       "\n",
       "        239       240       241       242       243       244       245  \\\n",
       "0  0.005269  0.001904 -0.004034 -0.000504  0.000648 -0.003017  0.002648   \n",
       "1 -0.007044  0.000725  0.003753 -0.003669  0.004366  0.000346 -0.002265   \n",
       "2  0.005342 -0.001487 -0.002336  0.001350 -0.000399 -0.001024  0.004213   \n",
       "3  0.007607 -0.000301 -0.004660 -0.000406 -0.003096  0.000738  0.005147   \n",
       "4 -0.006786  0.000333  0.002242  0.000701  0.001069 -0.001076 -0.003187   \n",
       "\n",
       "        246       247       248       249       250       251       252  \\\n",
       "0 -0.001625 -0.001297 -0.000094 -0.004509  0.003095 -0.001226  0.002629   \n",
       "1  0.003577  0.002273 -0.002026  0.004484 -0.002944  0.003495  0.000052   \n",
       "2 -0.001465 -0.002851  0.001797 -0.004204  0.002436 -0.004156  0.001994   \n",
       "3 -0.005901 -0.001247  0.001218 -0.005083  0.005849 -0.005977  0.001562   \n",
       "4  0.002563 -0.000596 -0.002998  0.002461 -0.002048  0.004591 -0.000857   \n",
       "\n",
       "        253       254       255       256       257       258       259  \\\n",
       "0 -0.000670 -0.001829  0.004608 -0.002525  0.003969  0.004466 -0.001154   \n",
       "1 -0.001855  0.002256 -0.005978  0.001470 -0.001730 -0.007466  0.000714   \n",
       "2 -0.000390 -0.002560  0.005552 -0.003326  0.004705  0.003882 -0.001368   \n",
       "3 -0.000601 -0.006528  0.009888 -0.003654  0.007549  0.006284 -0.001845   \n",
       "4 -0.001010  0.001105 -0.006123  0.001201 -0.002951 -0.003802  0.003183   \n",
       "\n",
       "        260       261       262       263       264       265       266  \\\n",
       "0 -0.000780  0.003627 -0.000036 -0.003140  0.001304  0.002242 -0.000502   \n",
       "1  0.003847 -0.002310  0.004063  0.006320 -0.000374  0.002189 -0.003890   \n",
       "2 -0.003854  0.004466 -0.001267 -0.003761  0.001173 -0.000695  0.002421   \n",
       "3 -0.003697  0.004432 -0.000375 -0.005279  0.003366  0.002551  0.000330   \n",
       "4  0.003035  0.000445  0.003664  0.003408 -0.002762  0.000704 -0.000403   \n",
       "\n",
       "        267       268       269       270       271       272       273  \\\n",
       "0 -0.002471 -0.003521  0.000792  0.001908 -0.004090 -0.003652  0.001819   \n",
       "1  0.002332  0.005065 -0.003224 -0.002985  0.004790  0.003122 -0.001942   \n",
       "2 -0.000214 -0.005842  0.002158  0.003106 -0.004669 -0.004021  0.000652   \n",
       "3 -0.002119 -0.007686  0.000762  0.001368 -0.005267 -0.006276  0.000081   \n",
       "4  0.001311  0.003799 -0.000778 -0.002040  0.003376  0.002739  0.000199   \n",
       "\n",
       "        274       275       276       277       278       279       280  \\\n",
       "0 -0.001948  0.000690 -0.001586 -0.001894  0.001636 -0.005740 -0.001457   \n",
       "1  0.001339 -0.000518  0.003748  0.000686 -0.006913  0.008089 -0.000046   \n",
       "2 -0.002898  0.001382 -0.006383 -0.001492  0.004466 -0.006580  0.001040   \n",
       "3 -0.003338 -0.000263 -0.004876 -0.001202  0.007144 -0.010689 -0.000544   \n",
       "4  0.000762  0.002247  0.004725 -0.000520 -0.003601  0.005679 -0.001363   \n",
       "\n",
       "        281       282       283       284       285       286       287  \\\n",
       "0 -0.001671 -0.002629 -0.001670  0.000374  0.002383  0.005808  0.004193   \n",
       "1  0.003386  0.002064  0.001925  0.001520 -0.003888 -0.004887 -0.007732   \n",
       "2 -0.004500 -0.001469 -0.001158 -0.000540  0.003210  0.006293  0.004049   \n",
       "3 -0.002578 -0.003413  0.001917  0.000163  0.004022  0.006001  0.006420   \n",
       "4  0.001856  0.000195 -0.000284 -0.000259 -0.000626 -0.000305 -0.004186   \n",
       "\n",
       "        288       289       290       291       292       293       294  \\\n",
       "0  0.004941  0.000361 -0.001459  0.000807 -0.003020 -0.003659  0.003299   \n",
       "1 -0.003013  0.001670 -0.000092 -0.001938  0.002807  0.005617 -0.001517   \n",
       "2  0.004019 -0.002533  0.001201 -0.000764 -0.001526 -0.005170  0.004062   \n",
       "3  0.005837 -0.001277  0.002825 -0.001682 -0.001474 -0.006860  0.004108   \n",
       "4 -0.000203  0.001272 -0.002241  0.001150  0.003393  0.004527 -0.001406   \n",
       "\n",
       "        295       296       297       298       299  \n",
       "0  0.005322  0.003322  0.000451 -0.000637 -0.006433  \n",
       "1 -0.005866 -0.005291 -0.003137  0.001113  0.009443  \n",
       "2  0.007125  0.004708  0.000588  0.000006 -0.007759  \n",
       "3  0.007494  0.005744 -0.001263 -0.002888 -0.010536  \n",
       "4 -0.004191 -0.003468  0.001180  0.001229  0.008381  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "pd.options.display.max_rows = 90\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "df = pd.read_csv(T_matrix_full_path, names=range(300))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./test_l3_l2_T/T/de_de_T.csv'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_matrix_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set list of T_matrix full paths\n",
    "T_matrix_dir = \"./test_l3_l2_T/T\"\n",
    "T_matrix_names = !ls $T_matrix_dir\n",
    "\n",
    "T_matrix_full_paths = []\n",
    "for T_matrix_name in T_matrix_names:\n",
    "    T_matrix_loc = T_matrix_dir+T_matrix_name\n",
    "    T_matrix_full_paths += [T_matrix_loc]\n",
    "\n",
    "# Load T_matrix into memory\n",
    "load_path = T_matrix_full_paths[2]\n",
    "print(load_path)\n",
    "file = open (\"./T_Matrices_examples/T_matrix_de_es.pkl\",'rb')\n",
    "file.seek(0)\n",
    "object_file = pickle.load(file)\n",
    "\n",
    "\"\"\"\n",
    "with open(r\"./T_Matrices_examples/T_matrix_de_es.pkl\", 'rb') as f:\n",
    "    T_matrix = pickle.load(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "     U,s,Vh = SVD(T)\n",
    "        \n",
    "        s1 = log(s)\n",
    "    \n",
    "        \n",
    "        for stat in stats:\n",
    "            svd[stat,translation[1],translation[2]] = stat_calc(stat, s, fro, acc)\n",
    "            svd1[stat,translation[1],translation[2]] = stat_calc(stat, s1, fro, acc)\n",
    "            \n",
    "        \n",
    "    #Exporting DataFrames for SVD Heatmaps\n",
    "    \n",
    "    s_df = make_df(languages,languages)\n",
    "    s1_df = make_df(languages,languages)\n",
    "    \n",
    "\n",
    "    for stat in stats:\n",
    "        for lang1 in languages:\n",
    "            for lang2 in languages:\n",
    "                s_df.set_value(lang1,lang2,svd[stat,lang1,lang2])\n",
    "                s1_df.set_value(lang1,lang2,svd1[stat,lang1,lang2])\n",
    "\n",
    "        s_df.to_csv('../HeatmapData/T/s_{}.csv'.format(stat),columns = languages)\n",
    "        s1_df.to_csv('../HeatmapData/T/s1_{}.csv'.format(stat),columns = languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "***** NOTE THE BELOW HAS BEEN MOVED TO DRIVER NOTEBOOK CURRENTLY IN CODE *******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "The Isomantics algorithm consists of the following stages:\n",
    "### **(Stage 0)** Prepare vocabulary\n",
    "* currently prepared languages:\n",
    "    1. English\n",
    "    2. Russian\n",
    "    3. German\n",
    "    4. French\n",
    "    5. Italian\n",
    "    6. Chinese \n",
    "    \n",
    "### **(Stage 1)** Word embeddings.  Using `fasttext` or `word2vec` we embed the vocab for each of the languages\n",
    "### **(Stage 2)** Train translation matrices:\n",
    "\n",
    "* Training set:\n",
    "    * For two given languages $Lg_1$ and $Lg_2$, we create a training set $\\Omega_{(Lg_1,Lg_2)}$ as follows:\n",
    "        1. For each $word_i$ in language 1, find the direct translation $\\widehat{word_i}$ in language 2.\n",
    "        2. Find vector embeddings $w_i\\in Lg_1$ and $\\widehat{w_i}\\in Lg_2$ of $word_i$ and $\\widehat{word_i}$ respectively.\n",
    "        3. Add the pair $<w_i,\\widehat{w_i}>$ to the training set $\\Omega_{(Lg_1,Lg_2)}$\n",
    "            * **Note** we found that training only for for only the the top 5-10k most popular terms in  $\\Omega_{(Lg_1,Lg_2)}$ generates the best word-to-word translation results on out of sample test sets.\n",
    "* Building the Cost function:\n",
    "    * Loss function for the learning process:\n",
    "        * $ Loss(T_{Lg_1,Lg_2})= ||Tw_i - \\widehat{w_i}||^2_2 $\n",
    "    * Regularization terms:\n",
    "        * Over fitting Regularizer:\n",
    "            * $Reg_{Frobenius}(T_{Lg_1,Lg_2}) = ||T_{Lg_1,Lg_2}||_2$\n",
    "        * Normality Regularizer:\n",
    "            * $Reg_{Normality}(T_{Lg_1,Lg_2}) = ||T_{Lg_1,Lg_2}^{T}T_{Lg_1,Lg_2} - T_{Lg_1,Lg_2}T_{Lg_1,Lg_2}^T||_2$\n",
    "                * **Note** The Normality Regularizer is used to ensure that the resulting matrix is diagonalizable.\n",
    "\n",
    "\n",
    "#### Full cost function:\n",
    "$$ J(T_{Lg_1,Lg_2})= Loss(T_{Lg_1,Lg_2}) + \\lambda_{1}Reg_{Frobenius}(T_{Lg_1,Lg_2}) + \\lambda_{2}Reg_{Normality}(T_{Lg_1,Lg_2}) $$  \n",
    "\n",
    "### **(Stage 3)** Translation Spectral Analysis:\n",
    "* Factor the matrix $T_{Lg_1,Lg_2} = U\\Sigma V^T$ where $U$ and $V$ are orthonormal (rotation) matrices and $\\Sigma$ gives the eigenvalues of $T_{Lg_1,Lg_2}$  or the \"*Translation spectrum*\"\n",
    "* Run a statistical analysis of the spectral values associated with each pair of languages.\n",
    "    1. mean\n",
    "    2. median\n",
    "    3. max value\n",
    "    4. min value\n",
    "    5. standard deviation\n",
    "\n",
    "* Compare the statistical spectral analysis across different language pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Stage 0) Prepare vocabulary:\n",
    "\n",
    "# TODO \n",
    " * add details on where the vocab was downloaded from\n",
    " * point to where the data is in the repo\n",
    " * add instructions on where to call it in the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Stages 1 and 2) \n",
    "1. Word embeddings. Using fasttext or word2vec we embed the vocab for each of the languages\n",
    "2. Train translation matrices:\n",
    "\n",
    "# TODO \n",
    " * add details on where the vocab is located\n",
    " * point to where the embeddings are located\n",
    " * Test following code on embedding process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import tools for running Spectral decomposition\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import ismtools\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO script this section and call the script from bash in this cell\n",
    "    # add the -a for setting calculate_KNN = True\n",
    "# TODO?? put manual list of translations into ismtools or another imported .py\n",
    "\n",
    "#Set parameter on calculate KNN (need to change for -a sysarg)\n",
    "calculate_KNN = False\n",
    "\n",
    "languages = ['en','ru','de','es','fr','it', 'zh-CN']\n",
    "for lang1 in languages:\n",
    "    for lang2 in languages:\n",
    "        translations.append(('fasttext_top',lang1, lang2))\n",
    "\n",
    "for translation in translations:\n",
    "    embedding, lg1, lg2 = translation\n",
    "    # Vocab/Vectors/Dicts\n",
    "    lg1_vocab, lg1_vectors, lg2_vocab, lg2_vectors = \\\n",
    "        pickle_rw((lg1 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                  (lg1 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                  (lg2 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                  (lg2 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                  write=False)\n",
    "    lg1_dict = make_dict(lg1_vocab, lg1_vectors)\n",
    "    lg2_dict = make_dict(lg2_vocab, lg2_vectors)\n",
    "\n",
    "    print('Translation: '+lg1+'->'+lg2+'\\n')\n",
    "\n",
    "    # Train/Test Vocab/Vectors\n",
    "    vocab_train, vocab_test = vocab_train_test(embedding, lg1, lg2, lg1_vocab)\n",
    "    X_train, X_test, y_train, y_test = vectors_train_test(vocab_train,\n",
    "                                                          vocab_test,lg1_dict,lg2_dict)\n",
    "    \n",
    "    # Fit tranlation matrix to training data\n",
    "    model, history, T, tf, I, M, fro = translation_matrix(X_train, y_train)\n",
    "    \n",
    "    if calculate_KNN:\n",
    "        results_df = translation_results(X_test, y_test, vocab_test, T,\n",
    "                                     lg2_vectors, lg2_vocab)\n",
    "        acc = T_norm_EDA(results_df)\n",
    "\n",
    "\"\"\"\n",
    "TODO create standardized dumping location for the translation matrix and its meta data.\n",
    "- pickel dump based on the dir structure in the folders\n",
    "\"\"\"        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Stage 3) Translation Spectral Analysis\n",
    "\n",
    "# TODO \n",
    " * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./T_Matrices_examples/T_matrix_de_es.pkl\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-85616075e742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"./T_Matrices_examples/T_matrix_de_es.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mobject_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \"\"\"\n",
      "\u001b[0;32m/Users/mtamir/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m   1382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mtamir/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/mtamir/anaconda/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_eof\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_eof\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set list of T_matrix full paths\n",
    "T_matrix_dir = \"./T_Matrices_examples/\"\n",
    "T_matrix_names = !ls $T_matrix_dir\n",
    "\n",
    "T_matrix_full_paths = []\n",
    "for T_matrix_name in T_matrix_names:\n",
    "    T_matrix_loc = T_matrix_dir+T_matrix_name\n",
    "    T_matrix_full_paths += [T_matrix_loc]\n",
    "\n",
    "# Load T_matrix into memory\n",
    "load_path = T_matrix_full_paths[2]\n",
    "print(load_path)\n",
    "file = open (\"./T_Matrices_examples/T_matrix_de_es.pkl\",'rb')\n",
    "file.seek(0)\n",
    "object_file = pickle.load(file)\n",
    "\n",
    "\"\"\"\n",
    "with open(r\"./T_Matrices_examples/T_matrix_de_es.pkl\", 'rb') as f:\n",
    "    T_matrix = pickle.load(f)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "U,s,Vh = SVD(T)\n",
    "\n",
    "s1 = log(s)\n",
    "\n",
    "\n",
    "for stat in stats:\n",
    "    svd[stat,translation[1],translation[2]] = stat_calc(stat, s, fro, acc)\n",
    "    svd1[stat,translation[1],translation[2]] = stat_calc(stat, s1, fro, acc)\n",
    "\n",
    "\n",
    "#Exporting DataFrames for SVD Heatmaps\n",
    "\n",
    "s_df = make_df(languages,languages)\n",
    "s1_df = make_df(languages,languages)\n",
    "\n",
    "\n",
    "for stat in stats:\n",
    "    for lang1 in languages:\n",
    "        for lang2 in languages:\n",
    "            s_df.set_value(lang1,lang2,svd[stat,lang1,lang2])\n",
    "            s1_df.set_value(lang1,lang2,svd1[stat,lang1,lang2])\n",
    "\n",
    "    s_df.to_csv('../HeatmapData/T/s_{}.csv'.format(stat),columns = languages)\n",
    "    s1_df.to_csv('../HeatmapData/T/s1_{}.csv'.format(stat),columns = languages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Manually set list of translations (embedding, lg1, lg2)\n",
    "    \n",
    "    svds = ['s','s1']\n",
    "    languages = ['en','ru','de','es','fr','it', 'zh-CN']\n",
    "    stats = ['min','max','mean','median','std','fro','acc']\n",
    "    \n",
    "    translations=[]\n",
    "    \n",
    "    for lang1 in languages:\n",
    "        for lang2 in languages:\n",
    "            translations.append(('fasttext_top',lang1, lang2))\n",
    "    \n",
    "    svd = {}\n",
    "    svd1 = {}\n",
    "    \n",
    "    for translation in translations:\n",
    "        embedding, lg1, lg2 = translation\n",
    "        # Vocab/Vectors/Dicts\n",
    "        lg1_vocab, lg1_vectors, lg2_vocab, lg2_vectors = \\\n",
    "            pickle_rw((lg1 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg1 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vocab', 0),\n",
    "                      (lg2 + '_' + embedding.split('_')[0] + '_vectors', 0),\n",
    "                      write=False)\n",
    "        lg1_dict = make_dict(lg1_vocab, lg1_vectors)\n",
    "        lg2_dict = make_dict(lg2_vocab, lg2_vectors)\n",
    "\n",
    "        print('Translation: '+lg1+'->'+lg2+'\\n')\n",
    "\n",
    "        # Train/Test Vocab/Vectors\n",
    "        vocab_train, vocab_test = vocab_train_test(embedding, lg1, lg2, lg1_vocab)\n",
    "        X_train, X_test, y_train, y_test = vectors_train_test(vocab_train,\n",
    "                                                              vocab_test,lg1_dict,lg2_dict)\n",
    " \n",
    "        \n",
    "        # Fit tranlation matrix to training data\n",
    "        model, history, T, tf,I, M, fro = translation_matrix(X_train, y_train)\n",
    "        \n",
    "        results_df = translation_results(X_test, y_test, vocab_test, T,\n",
    "                                         lg2_vectors, lg2_vocab)\n",
    "        acc = T_norm_EDA(results_df)\n",
    "        \n",
    "        U,s,Vh = SVD(T)\n",
    "        \n",
    "        s1 = log(s)\n",
    "    \n",
    "        \n",
    "        for stat in stats:\n",
    "            svd[stat,translation[1],translation[2]] = stat_calc(stat, s, fro, acc)\n",
    "            svd1[stat,translation[1],translation[2]] = stat_calc(stat, s1, fro, acc)\n",
    "            \n",
    "        \n",
    "    #Exporting DataFrames for SVD Heatmaps\n",
    "    \n",
    "    s_df = make_df(languages,languages)\n",
    "    s1_df = make_df(languages,languages)\n",
    "    \n",
    "\n",
    "    for stat in stats:\n",
    "        for lang1 in languages:\n",
    "            for lang2 in languages:\n",
    "                s_df.set_value(lang1,lang2,svd[stat,lang1,lang2])\n",
    "                s1_df.set_value(lang1,lang2,svd1[stat,lang1,lang2])\n",
    "\n",
    "        s_df.to_csv('../HeatmapData/T/s_{}.csv'.format(stat),columns = languages)\n",
    "        s1_df.to_csv('../HeatmapData/T/s1_{}.csv'.format(stat),columns = languages)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Translation Matrix Results  \n",
    "## En to Ru Fasttext_Random  \n",
    "- En Vocabulary Size = 1,259,685  \n",
    "- En Embedding Length = 300  \n",
    "- Ru Vocabulary Size = 944,211  \n",
    "- Ru Embedding Length = 300  \n",
    "- Train Size = 5,000  \n",
    "- Test Size = 1,500  \n",
    "- <b>Test Accuracy = 3.9%</b>  \n",
    "\n",
    "#### Test L2 Norms  \n",
    "- X_norm: L2 norms for En test vectors  \n",
    "- y_norm: L2 norms for Ru test vectors  \n",
    "- yhat_norm: L2 norms for X.dot(T) test vectors (T = translation matrix)  \n",
    "- yhat_neighbor norm: L2 norms for nearest neighborto X.dot(T) in y test vectors  \n",
    "![](../images/en_ru_fasttext_random_T_norm.png)  \n",
    "\n",
    "#### Translation Matrix Isotropy  \n",
    "- Isotropy = 32.3%  \n",
    "![](../images/en_ru_fasttext_random_T_isotropy.png)  \n",
    "\n",
    "## En to Ru Fasttext_Top  \n",
    "- En Vocabulary Size = 1,259,685  \n",
    "- En Embedding Length = 300  \n",
    "- Ru Vocabulary Size = 944,211  \n",
    "- Ru Embedding Length = 300  \n",
    "- Train Size = 5,000  \n",
    "- Test Size = 1,500  \n",
    "- <b>Test Accuracy = 46.3%</b>  \n",
    "\n",
    "#### Test L2 Norms  \n",
    "- X_norm: L2 norms for En test vectors  \n",
    "- y_norm: L2 norms for Ru test vectors  \n",
    "- yhat_norm: L2 norms for X.dot(T) test vectors (T = translation matrix)  \n",
    "- yhat_neighbor norm: L2 norms for nearest neighborto X.dot(T) in y test vectors  \n",
    "![](../images/en_ru_fasttext_top_T_norm.png)  \n",
    "\n",
    "#### Translation Matrix Isotropy  \n",
    "- Isotropy = 38.2%  \n",
    "![](../images/en_ru_fasttext_top_T_isotropy.png)  \n",
    "\n",
    "## En to De Fasttext_Random  \n",
    "- En Vocabulary Size = 1,259,685  \n",
    "- En Embedding Length = 300  \n",
    "- De Vocabulary Size = 1,137,616  \n",
    "- De Embedding Length = 300  \n",
    "- Train Size = 5,000  \n",
    "- Test Size = 1,500  \n",
    "- <b>Test Accuracy = 21.9%</b>  \n",
    "\n",
    "#### Test L2 Norms  \n",
    "- X_norm: L2 norms for En test vectors  \n",
    "- y_norm: L2 norms for De test vectors  \n",
    "- yhat_norm: L2 norms for X.dot(T) test vectors (T = translation matrix)  \n",
    "- yhat_neighbor norm: L2 norms for nearest neighborto X.dot(T) in y test vectors  \n",
    "![](../images/en_de_fasttext_random_T_norm.png)  \n",
    "\n",
    "#### Translation Matrix Isotropy  \n",
    "- Isotropy = 35.6%  \n",
    "![](../images/en_de_fasttext_random_T_isotropy.png)  \n",
    "\n",
    "## En to De Fasttext_Top  \n",
    "- En Vocabulary Size = 1,259,685  \n",
    "- En Embedding Length = 300  \n",
    "- De Vocabulary Size = 1,137,616  \n",
    "- De Embedding Length = 300  \n",
    "- Train Size = 5,000  \n",
    "- Test Size = 1,500  \n",
    "- <b>Test Accuracy = 63.6%</b>  \n",
    "\n",
    "#### Test L2 Norms  \n",
    "- X_norm: L2 norms for En test vectors  \n",
    "- y_norm: L2 norms for De test vectors  \n",
    "- yhat_norm: L2 norms for X.dot(T) test vectors (T = translation matrix)  \n",
    "- yhat_neighbor norm: L2 norms for nearest neighborto X.dot(T) in y test vectors  \n",
    "![](../images/en_de_fasttext_top_T_norm.png)  \n",
    "\n",
    "#### Translation Matrix Isotropy  \n",
    "- Isotropy = 43.4%  \n",
    "![](../images/en_de_fasttext_top_T_isotropy.png)  \n",
    "\n",
    "## En to It Zeroshot  \n",
    "- En Vocabulary Size = 200,000  \n",
    "- En Embedding Length = 300  \n",
    "- It Vocabulary Size = 200,000  \n",
    "- It Embedding Length = 300  \n",
    "- Train Size = 5,000  \n",
    "- Test Size = 1,869  \n",
    "- <b>Test Accuracy = 27.9%</b>  \n",
    "\n",
    "#### Test L2 Norms  \n",
    "- X_norm: L2 norms for En test vectors  \n",
    "- y_norm: L2 norms for It test vectors  \n",
    "- yhat_norm: L2 norms for X.dot(T) test vectors (T = translation matrix)  \n",
    "- yhat_neighbor norm: L2 norms for nearest neighborto X.dot(T) in y test vectors  \n",
    "![](../images/en_it_zeroshot_T_norm.png)  \n",
    "\n",
    "#### Translation Matrix Isotropy  \n",
    "- Isotropy = 46.6%  \n",
    "![](../images/en_it_zeroshot_T_isotropy.png)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
